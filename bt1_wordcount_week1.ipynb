{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1bl-q-3qD33nWolMbtZvtzgBDZs5CfNCq","authorship_tag":"ABX9TyNaRJDnK7rm+X5lQlv7bqiy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0rcqMVPgr9x","executionInfo":{"status":"ok","timestamp":1611477000629,"user_tz":-420,"elapsed":39050,"user":{"displayName":"Đoàn Bá Tùng","photoUrl":"","userId":"02086423496280431289"}},"outputId":"b7c955c0-c65c-41c3-ce6e-d2552cdfcd61"},"source":["pip install pyspark\r\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n","\u001b[K     |████████████████████████████████| 204.2MB 58kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 43.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612242 sha256=8eac6cc34bdae704dbaab2bd818ed8ed628fd3197a6fcbc14d8ec2279e3652a7\n","  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xMmokQttg7yQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9gblVsufaXO","executionInfo":{"status":"ok","timestamp":1611477205003,"user_tz":-420,"elapsed":1490,"user":{"displayName":"Đoàn Bá Tùng","photoUrl":"","userId":"02086423496280431289"}},"outputId":"7b111359-820d-4e04-a603-6ecbd0cbc1ac"},"source":["import pyspark\r\n","from pyspark import SparkContext, SparkConf\r\n","import collections\r\n","\r\n","conf = SparkConf().setMaster(\"local\").setAppName(\"word_counting\")\r\n","sc = SparkContext.getOrCreate(conf=conf)\r\n","\r\n","file = sc.textFile(\"/content/text.txt\").first().split(\" \")\r\n","rdd = sc.parallelize(file)\r\n","\r\n","counts = rdd.map(lambda word : (word,1)).reduceByKey(lambda x,y: x+y) \r\n","\r\n","max_count = counts.reduce(lambda x, y : x if x[1] > y[1] else y)\r\n","\r\n","result = ', '.join(map(str,[i[0] for i in counts.collect() if(i[1] == max_count[1])]))\r\n","\r\n","print(\"Những từ có trong file text.txt: \\n\", counts.collect())\r\n","\r\n","print(\"\\nTừ '\" + result + \"' xuất hiện nhiều nhất trong file (\"+ str(max_count[1]) + \" lần)\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Những từ có trong file text.txt: \n"," [('một', 1), ('hai', 1), ('ba', 1), ('bốn', 3), ('năm', 2)]\n","\n","Từ 'bốn' xuất hiện nhiều nhất trong file (3 lần)\n"],"name":"stdout"}]}]}